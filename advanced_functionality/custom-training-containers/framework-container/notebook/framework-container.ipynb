{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "timely-mouth",
   "metadata": {
    "papermill": {
     "duration": 0.012514,
     "end_time": "2021-06-21T00:17:24.092815",
     "exception": false,
     "start_time": "2021-06-21T00:17:24.080301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1>Custom Framework Container</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-dodge",
   "metadata": {
    "papermill": {
     "duration": 0.012454,
     "end_time": "2021-06-21T00:17:24.117859",
     "exception": false,
     "start_time": "2021-06-21T00:17:24.105405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook demonstrates how to build and use a simple custom Docker container for training with Amazon SageMaker that leverages on the sagemaker-training-toolkit library to define framework containers.\n",
    "A framework container is similar to a script-mode container, but in addition it loads a Python framework module that is used to configure the framework and then run the user-provided module.\n",
    "\n",
    "Reference documentation is available at https://github.com/aws/sagemaker-training-toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-camping",
   "metadata": {
    "papermill": {
     "duration": 0.012511,
     "end_time": "2021-06-21T00:17:24.142864",
     "exception": false,
     "start_time": "2021-06-21T00:17:24.130353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passive-consortium",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:24.173153Z",
     "iopub.status.busy": "2021-06-21T00:17:24.172393Z",
     "iopub.status.idle": "2021-06-21T00:17:25.397764Z",
     "shell.execute_reply": "2021-06-21T00:17:25.398121Z"
    },
    "papermill": {
     "duration": 1.242876,
     "end_time": "2021-06-21T00:17:25.398255",
     "exception": false,
     "start_time": "2021-06-21T00:17:24.155379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521695447989\n",
      "us-west-2\n",
      "arn:aws:iam::521695447989:role/ProdBuildSystemStack-ReleaseBuildRoleFB326D49-QK8LUA2UI1IC\n",
      "sagemaker-us-west-2-521695447989\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = \"sagemaker-training-containers/\"\n",
    "prefix = \"framework-container\"\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(\":\")[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-chart",
   "metadata": {
    "papermill": {
     "duration": 0.012783,
     "end_time": "2021-06-21T00:17:25.424381",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.411598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our custom framework container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "african-drinking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:25.453640Z",
     "iopub.status.busy": "2021-06-21T00:17:25.453086Z",
     "iopub.status.idle": "2021-06-21T00:17:25.634721Z",
     "shell.execute_reply": "2021-06-21T00:17:25.635131Z"
    },
    "papermill": {
     "duration": 0.198128,
     "end_time": "2021-06-21T00:17:25.635278",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.437150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: '../docker/Dockerfile'\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-protection",
   "metadata": {
    "papermill": {
     "duration": 0.013236,
     "end_time": "2021-06-21T00:17:25.661956",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.648720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "<ul>\n",
    "    <li>Start from Ubuntu 16.04</li>\n",
    "    <li>Define some variables to be used at build time to install Python 3</li>\n",
    "    <li>Some handful libraries are installed with apt-get</li>\n",
    "    <li>We then install Python 3 and create a symbolic link</li>\n",
    "    <li>We copy a .tar.gz package named <strong>custom_framework_training-1.0.0.tar.gz</strong> in the WORKDIR</li>\n",
    "    <li>We then install some Python libraries like numpy, pandas, ScikitLearn <strong>and the package we copied at the previous step</strong></li>\n",
    "    <li>We set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)</li>\n",
    "    <li>Finally, we set the value of the environment variable <strong>SAGEMAKER_TRAINING_MODULE</strong> to a python module in the training package we installed</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-northwest",
   "metadata": {
    "papermill": {
     "duration": 0.013099,
     "end_time": "2021-06-21T00:17:25.688160",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.675061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2>Training module</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-composer",
   "metadata": {
    "papermill": {
     "duration": 0.012979,
     "end_time": "2021-06-21T00:17:25.714245",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.701266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When looking at the Dockerfile above, you might be askiong yourself what the <strong>custom_framework_training-1.0.0.tar.gz</strong> package is.\n",
    "When building a framework container, sagemaker-training-toolkit allows you to specify a framework module that will be run first, and then invoke a user-provided module.\n",
    "\n",
    "The advantage of using this approach is that you can use the framework module to configure the framework of choice or apply any settings related to the libraries installed in the environment, and then run the user module (we will see shortly how).\n",
    "\n",
    "Our framework module is part of a Python package - that you can find in the folder ../package/ - distributed as a .tar.gz by the Python setuptools library (https://setuptools.readthedocs.io/en/latest/).\n",
    "\n",
    "Setuptools uses a setup.py file to build the package. Following is the content of this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacterial-invention",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:25.744574Z",
     "iopub.status.busy": "2021-06-21T00:17:25.744078Z",
     "iopub.status.idle": "2021-06-21T00:17:25.925534Z",
     "shell.execute_reply": "2021-06-21T00:17:25.925091Z"
    },
    "papermill": {
     "duration": 0.198364,
     "end_time": "2021-06-21T00:17:25.925643",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.727279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: '../package/setup.py'\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../package/setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-wallace",
   "metadata": {
    "papermill": {
     "duration": 0.013563,
     "end_time": "2021-06-21T00:17:25.953877",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.940314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This build script looks at the packages under the local src/ path and specifies the dependency on sagemaker-training. The training module contains the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-telephone",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:25.987070Z",
     "iopub.status.busy": "2021-06-21T00:17:25.984295Z",
     "iopub.status.idle": "2021-06-21T00:17:26.164817Z",
     "shell.execute_reply": "2021-06-21T00:17:26.164351Z"
    },
    "papermill": {
     "duration": 0.197749,
     "end_time": "2021-06-21T00:17:26.164929",
     "exception": false,
     "start_time": "2021-06-21T00:17:25.967180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: '../package/src/custom_framework_training/training.py'\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ../package/src/custom_framework_training/training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-stock",
   "metadata": {
    "papermill": {
     "duration": 0.013908,
     "end_time": "2021-06-21T00:17:26.192835",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.178927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The idea here is that we will use the <strong>entry_point.run()</strong> function of the sagemaker-training-toolkit library to execute the user-provided module.\n",
    "You might want to set additional framework-level configurations (e.g. parameter servers) before calling the user module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-demographic",
   "metadata": {
    "papermill": {
     "duration": 0.013684,
     "end_time": "2021-06-21T00:17:26.220317",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.206633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-contents",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:26.251883Z",
     "iopub.status.busy": "2021-06-21T00:17:26.251439Z",
     "iopub.status.idle": "2021-06-21T00:17:26.432447Z",
     "shell.execute_reply": "2021-06-21T00:17:26.431989Z"
    },
    "papermill": {
     "duration": 0.198465,
     "end_time": "2021-06-21T00:17:26.432563",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.234098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: cannot read infile: [Errno 2] No such file or directory: '../scripts/build_and_push.sh'\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-mexican",
   "metadata": {
    "papermill": {
     "duration": 0.014192,
     "end_time": "2021-06-21T00:17:26.461061",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.446869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "First, the script runs the <strong>setup.py</strong> to create the training package, which is copied under <strong>../docker/code/</strong>.\n",
    "\n",
    "Then it builds the Docker container, creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "front-institution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:26.495129Z",
     "iopub.status.busy": "2021-06-21T00:17:26.494490Z",
     "iopub.status.idle": "2021-06-21T00:17:26.640895Z",
     "shell.execute_reply": "2021-06-21T00:17:26.640339Z"
    },
    "papermill": {
     "duration": 0.166042,
     "end_time": "2021-06-21T00:17:26.641075",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.475033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-madagascar",
   "metadata": {
    "papermill": {
     "duration": 0.014993,
     "end_time": "2021-06-21T00:17:26.675503",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.660510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "delayed-stack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:26.708174Z",
     "iopub.status.busy": "2021-06-21T00:17:26.707704Z",
     "iopub.status.idle": "2021-06-21T00:17:26.710252Z",
     "shell.execute_reply": "2021-06-21T00:17:26.709775Z"
    },
    "papermill": {
     "duration": 0.020521,
     "end_time": "2021-06-21T00:17:26.710356",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.689835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521695447989.dkr.ecr.us-west-2.amazonaws.com/sagemaker-training-containers/framework-container:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest\".format(\n",
    "    account_id, region, ecr_repository_name\n",
    ")\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-banks",
   "metadata": {
    "papermill": {
     "duration": 0.014468,
     "end_time": "2021-06-21T00:17:26.739268",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.724800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Given the purpose of this example is explaining how to build custom framework containers, we are not going to train a real model. The script that will be executed does not define a specific training logic; it just outputs the configurations injected by SageMaker and implements a dummy training loop. Training data is also dummy. Let's analyze the script first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-earthquake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:26.774721Z",
     "iopub.status.busy": "2021-06-21T00:17:26.771581Z",
     "iopub.status.idle": "2021-06-21T00:17:27.500359Z",
     "shell.execute_reply": "2021-06-21T00:17:27.500785Z"
    },
    "papermill": {
     "duration": 0.747183,
     "end_time": "2021-06-21T00:17:27.500925",
     "exception": false,
     "start_time": "2021-06-21T00:17:26.753742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_files_in_path, save_model_artifacts\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(hp1, hp2, hp3, train_channel, validation_channel):\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in train channel: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mList of files in validation channel: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    print_files_in_path(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Dummy net.\u001b[39;49;00m\n",
      "    net = \u001b[34mNone\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Run training loop.\u001b[39;49;00m\n",
      "    epochs = \u001b[34m5\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epochs):\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mRunning epoch \u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "\n",
      "        time.sleep(\u001b[34m30\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCompleted epoch \u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x))\n",
      "\n",
      "    \u001b[37m# At the end of the training loop, we have to save model artifacts.\u001b[39;49;00m\n",
      "    model_dir = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    save_model_artifacts(model_dir + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, net)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# sagemaker-containers passes hyperparameters as arguments\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hp1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hp2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m50\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hp3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# This is a way to pass additional arguments when running as a script\u001b[39;49;00m\n",
      "    \u001b[37m# and use sagemaker-containers defaults to set their values when not specified.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    train(args.hp1, args.hp2, args.hp3, args.train, args.validation)\n"
     ]
    }
   ],
   "source": [
    "! pygmentize source_dir/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-addiction",
   "metadata": {
    "papermill": {
     "duration": 0.014868,
     "end_time": "2021-06-21T00:17:27.531026",
     "exception": false,
     "start_time": "2021-06-21T00:17:27.516158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked as a module by the framework container code, passing hyperparameters as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-flash",
   "metadata": {
    "papermill": {
     "duration": 0.014734,
     "end_time": "2021-06-21T00:17:27.560539",
     "exception": false,
     "start_time": "2021-06-21T00:17:27.545805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hired-secretariat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:27.596021Z",
     "iopub.status.busy": "2021-06-21T00:17:27.595549Z",
     "iopub.status.idle": "2021-06-21T00:17:28.043452Z",
     "shell.execute_reply": "2021-06-21T00:17:28.043842Z"
    },
    "papermill": {
     "duration": 0.468652,
     "end_time": "2021-06-21T00:17:28.043985",
     "exception": false,
     "start_time": "2021-06-21T00:17:27.575333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-521695447989/framework-container/train/dummy.csv\n",
      "s3://sagemaker-us-west-2-521695447989/framework-container/val/dummy.csv\n"
     ]
    }
   ],
   "source": [
    "! echo \"val1, val2, val3\" > dummy.csv\n",
    "print(sagemaker_session.upload_data(\"dummy.csv\", bucket, prefix + \"/train\"))\n",
    "print(sagemaker_session.upload_data(\"dummy.csv\", bucket, prefix + \"/val\"))\n",
    "! rm dummy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-contest",
   "metadata": {
    "papermill": {
     "duration": 0.015289,
     "end_time": "2021-06-21T00:17:28.076588",
     "exception": false,
     "start_time": "2021-06-21T00:17:28.061299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Framework containers enable dynamically running user-provided code loading it from Amazon S3, so we need to:\n",
    "<ul>\n",
    "    <li>Package the <strong>source_dir</strong> folder in a tar.gz archive</li>\n",
    "    <li>Upload the archive to Amazon S3</li>\n",
    "    <li>Specify the path to the archive in Amazon S3 as one of the parameters of the training job</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Note:</strong> these steps are executed automatically by the Amazon SageMaker Python SDK when using framework estimators for MXNet, Tensorflow, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surgical-prophet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:28.113483Z",
     "iopub.status.busy": "2021-06-21T00:17:28.112726Z",
     "iopub.status.idle": "2021-06-21T00:17:28.121414Z",
     "shell.execute_reply": "2021-06-21T00:17:28.121759Z"
    },
    "papermill": {
     "duration": 0.030033,
     "end_time": "2021-06-21T00:17:28.121880",
     "exception": false,
     "start_time": "2021-06-21T00:17:28.091847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sourcedir.tar.gz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "\n",
    "def create_tar_file(source_files, target=None):\n",
    "    if target:\n",
    "        filename = target\n",
    "    else:\n",
    "        _, filename = tempfile.mkstemp()\n",
    "\n",
    "    with tarfile.open(filename, mode=\"w:gz\") as t:\n",
    "        for sf in source_files:\n",
    "            # Add all files from the directory into the root of the directory structure of the tar\n",
    "            t.add(sf, arcname=os.path.basename(sf))\n",
    "    return filename\n",
    "\n",
    "\n",
    "create_tar_file([\"source_dir/train.py\", \"source_dir/utils.py\"], \"sourcedir.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "looking-turtle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:28.159777Z",
     "iopub.status.busy": "2021-06-21T00:17:28.159348Z",
     "iopub.status.idle": "2021-06-21T00:17:28.364809Z",
     "shell.execute_reply": "2021-06-21T00:17:28.365195Z"
    },
    "papermill": {
     "duration": 0.227975,
     "end_time": "2021-06-21T00:17:28.365334",
     "exception": false,
     "start_time": "2021-06-21T00:17:28.137359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-521695447989/framework-container/code/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sources = sagemaker_session.upload_data(\"sourcedir.tar.gz\", bucket, prefix + \"/code\")\n",
    "print(sources)\n",
    "! rm sourcedir.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-armor",
   "metadata": {
    "papermill": {
     "duration": 0.016063,
     "end_time": "2021-06-21T00:17:28.397803",
     "exception": false,
     "start_time": "2021-06-21T00:17:28.381740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When starting the training job, we need to let the sagemaker-training-toolkit library know where the sources are stored in Amazon S3 and what is the module to be invoked. These parameters are specified through the following reserved hyperparameters (these reserved hyperparameters are injected automatically when using framework estimators of the Amazon SageMaker Python SDK):\n",
    "<ul>\n",
    "    <li>sagemaker_program</li>\n",
    "    <li>sagemaker_submit_directory</li>\n",
    "</ul>\n",
    "\n",
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-halifax",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lightweight-writer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:17:28.437063Z",
     "iopub.status.busy": "2021-06-21T00:17:28.436595Z",
     "iopub.status.idle": "2021-06-21T00:17:29.135520Z",
     "shell.execute_reply": "2021-06-21T00:17:29.134769Z"
    },
    "papermill": {
     "duration": 0.72197,
     "end_time": "2021-06-21T00:17:29.135713",
     "exception": true,
     "start_time": "2021-06-21T00:17:28.413743",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Using the short-lived AWS credentials found in session. They might expire while running.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'docker': 'docker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2599e4c6529d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_config\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \"\"\"\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mcompose_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_ecr_login_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0m_pull_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_ecr_login_if_needed\u001b[0;34m(boto_session, image)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# do we have the image?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_check_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"docker images -q %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_check_output\u001b[0;34m(cmd, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'docker': 'docker'"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(\n",
    "    {\n",
    "        \"sagemaker_program\": \"train.py\",\n",
    "        \"sagemaker_submit_directory\": sources,\n",
    "        \"hp1\": \"value1\",\n",
    "        \"hp2\": 300,\n",
    "        \"hp3\": 0.001,\n",
    "    }\n",
    ")\n",
    "\n",
    "est = sagemaker.estimator.Estimator(\n",
    "    container_image_uri,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"local\",\n",
    "    base_job_name=prefix,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.s3_input(\n",
    "    \"s3://{0}/{1}/train/\".format(bucket, prefix), content_type=\"text/csv\"\n",
    ")\n",
    "val_config = sagemaker.session.s3_input(\n",
    "    \"s3://{0}/{1}/val/\".format(bucket, prefix), content_type=\"text/csv\"\n",
    ")\n",
    "\n",
    "est.fit({\"train\": train_config, \"validation\": val_config})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-partition",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<h3>Training with a custom SDK framework estimator</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-thong",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "As you have seen, in the previous steps we had to upload our code to Amazon S3 and then inject reserved hyperparameters to execute training. In order to facilitate this task, you can also try defining a custom framework estimator using the Amazon SageMaker Python SDK and run training with that class, which will take care of managing these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-diameter",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Framework\n",
    "\n",
    "\n",
    "class CustomFramework(Framework):\n",
    "    def __init__(\n",
    "        self,\n",
    "        entry_point,\n",
    "        source_dir=None,\n",
    "        hyperparameters=None,\n",
    "        py_version=\"py3\",\n",
    "        framework_version=None,\n",
    "        image_name=None,\n",
    "        distributions=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(CustomFramework, self).__init__(\n",
    "            entry_point, source_dir, hyperparameters, image_name=image_name, **kwargs\n",
    "        )\n",
    "\n",
    "    def _configure_distribution(self, distributions):\n",
    "        return\n",
    "\n",
    "    def create_model(\n",
    "        self,\n",
    "        model_server_workers=None,\n",
    "        role=None,\n",
    "        vpc_config_override=None,\n",
    "        entry_point=None,\n",
    "        source_dir=None,\n",
    "        dependencies=None,\n",
    "        image_name=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "est = CustomFramework(\n",
    "    image_name=container_image_uri,\n",
    "    role=role,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"source_dir/\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"local\",  # we use local mode\n",
    "    # train_instance_type='ml.m5.xlarge',\n",
    "    base_job_name=prefix,\n",
    "    hyperparameters={\"hp1\": \"value1\", \"hp2\": \"300\", \"hp3\": \"0.001\"},\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.s3_input(\n",
    "    \"s3://{0}/{1}/train/\".format(bucket, prefix), content_type=\"text/csv\"\n",
    ")\n",
    "val_config = sagemaker.session.s3_input(\n",
    "    \"s3://{0}/{1}/val/\".format(bucket, prefix), content_type=\"text/csv\"\n",
    ")\n",
    "\n",
    "est.fit({\"train\": train_config, \"validation\": val_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-baker",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.401781,
   "end_time": "2021-06-21T00:17:29.640978",
   "environment_variables": {},
   "exception": true,
   "input_path": "framework-container.ipynb",
   "output_path": "/opt/ml/processing/output/framework-container-2021-06-21-00-12-57.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-21T00:17:23.239197",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
