{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exempt-compatibility",
   "metadata": {
    "papermill": {
     "duration": 0.012823,
     "end_time": "2021-06-17T00:16:00.535325",
     "exception": false,
     "start_time": "2021-06-17T00:16:00.522502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FAIRSeq in Amazon SageMaker: Translation task - German to English - Distributed / multi machine training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-hollow",
   "metadata": {
    "papermill": {
     "duration": 0.012553,
     "end_time": "2021-06-17T00:16:00.560679",
     "exception": false,
     "start_time": "2021-06-17T00:16:00.548126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Facebook AI Research (FAIR) Lab made available through the [FAIRSeq toolkit](https://github.com/pytorch/fairseq) their state-of-the-art Sequence to Sequence models. \n",
    "\n",
    "In this notebook, we will show you how to train a German to English translation model using a fully convolutional architecture on multiple GPUs and machines.\n",
    "\n",
    "## Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the regular SageMakerFullAccess permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy AmazonEC2ContainerRegistryFullAccess to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-carrier",
   "metadata": {
    "papermill": {
     "duration": 0.012582,
     "end_time": "2021-06-17T00:16:00.585788",
     "exception": false,
     "start_time": "2021-06-17T00:16:00.573206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare dataset\n",
    "\n",
    "To train the model, we will be using the IWSLT'14 dataset as descibed [here](https://github.com/pytorch/fairseq/tree/master/examples/translation#prepare-iwslt14sh). This was used in the IWSLT'14 German to English translation task: [\"Report on the 11th IWSLT evaluation campaign\" by Cettolo et al](http://workshop2014.iwslt.org/downloads/proceeding.pdf).\n",
    "\n",
    "First, we'll download the dataset and start the pre-processing. Among other steps, this pre-processing cleans the tokens and applys BPE encoding as you can see [here](https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-iwslt14.sh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binary-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-17 21:28:10--  https://raw.githubusercontent.com/pytorch/fairseq/master/examples/translation/prepare-iwslt14.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2981 (2.9K) [text/plain]\n",
      "Saving to: ‘prepare-iwslt14.sh’\n",
      "\n",
      "prepare-iwslt14.sh  100%[===================>]   2.91K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-06-17 21:28:10 (61.4 MB/s) - ‘prepare-iwslt14.sh’ saved [2981/2981]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/pytorch/fairseq/master/examples/translation/prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latest-appearance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T00:16:00.615862Z",
     "iopub.status.busy": "2021-06-17T00:16:00.614093Z",
     "iopub.status.idle": "2021-06-17T00:16:09.766225Z",
     "shell.execute_reply": "2021-06-17T00:16:09.765809Z"
    },
    "papermill": {
     "duration": 9.168023,
     "end_time": "2021-06-17T00:16:09.766336",
     "exception": false,
     "start_time": "2021-06-17T00:16:00.598313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning Moses github repository (for tokenization scripts)...\n",
      "Cloning Subword NMT repository (for BPE pre-processing)...\n",
      "Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n",
      "Data not successfully downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chmod: cannot access '600': No such file or directory\n",
      "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
      "fatal: destination path 'subword-nmt' already exists and is not an empty directory.\n",
      "--2021-06-17 21:30:55--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n",
      "Resolving wit3.fbk.eu (wit3.fbk.eu)... 142.251.33.83, 2607:f8b0:400a:805::2013\n",
      "Connecting to wit3.fbk.eu (wit3.fbk.eu)|142.251.33.83|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2021-06-17 21:30:55 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd data\n",
    "chmod +x 600 prepare-iwslt14.sh\n",
    "\n",
    "# Download dataset and start pre-processing\n",
    "bash prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-prefix",
   "metadata": {
    "papermill": {
     "duration": 0.01315,
     "end_time": "2021-06-17T00:16:09.793261",
     "exception": false,
     "start_time": "2021-06-17T00:16:09.780111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next step is to apply the second set of pre-processing, which binarizes the dataset based on the source and target language. Full information on this script [here](https://github.com/pytorch/fairseq/blob/master/preprocess.py).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-porter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T00:16:09.823324Z",
     "iopub.status.busy": "2021-06-17T00:16:09.822842Z",
     "iopub.status.idle": "2021-06-17T00:16:11.122504Z",
     "shell.execute_reply": "2021-06-17T00:16:11.121640Z"
    },
    "papermill": {
     "duration": 1.316354,
     "end_time": "2021-06-17T00:16:11.122746",
     "exception": true,
     "start_time": "2021-06-17T00:16:09.806392",
     "status": "failed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq-git'...\n",
      "python: can't open file 'preprocess.py': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n# First we download fairseq in order to have access to the scripts\\ngit clone https://github.com/pytorch/fairseq.git fairseq-git\\ncd fairseq-git\\n\\n# Binarize the dataset:\\nTEXT=../data/iwslt14.tokenized.de-en\\npython preprocess.py --source-lang de --target-lang en \\\\\\n  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\\\\n  --destdir ..data/iwslt14.tokenized.de-en\\n'' returned non-zero exit status 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9892f7e97fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n# First we download fairseq in order to have access to the scripts\\ngit clone https://github.com/pytorch/fairseq.git fairseq-git\\ncd fairseq-git\\n\\n# Binarize the dataset:\\nTEXT=../data/iwslt14.tokenized.de-en\\npython preprocess.py --source-lang de --target-lang en \\\\\\n  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\\\\n  --destdir ..data/iwslt14.tokenized.de-en\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n# First we download fairseq in order to have access to the scripts\\ngit clone https://github.com/pytorch/fairseq.git fairseq-git\\ncd fairseq-git\\n\\n# Binarize the dataset:\\nTEXT=../data/iwslt14.tokenized.de-en\\npython preprocess.py --source-lang de --target-lang en \\\\\\n  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\\\\n  --destdir ..data/iwslt14.tokenized.de-en\\n'' returned non-zero exit status 2."
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# First we download fairseq in order to have access to the scripts\n",
    "git clone https://github.com/pytorch/fairseq.git fairseq-git\n",
    "cd fairseq-git\n",
    "\n",
    "# Binarize the dataset:\n",
    "TEXT=../data/iwslt14.tokenized.de-en\n",
    "\n",
    "python preprocess.py --source-lang de --target-lang en \\\n",
    "  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "  --destdir ..data/iwslt14.tokenized.de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-relevance",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The dataset is now all prepared for training on one of the FAIRSeq translation models. The next step is upload the data to Amazon S3 in order to make it available for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-sheffield",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Upload data to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-camcorder",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "account = sagemaker_session.boto_session.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-fairseq/datasets/iwslt14\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-operations",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(\n",
    "    path=\"data/iwslt14.tokenized.de-en\", bucket=bucket, key_prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-seating",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Next we need to register a Docker image in Amazon SageMaker that will contain the FAIRSeq code and that will be pulled at training and inference time to perform the respective training of the model and the serving of the precitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-shore",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Build FAIRSeq Translation task container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-sociology",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "chmod +x create_container.sh \n",
    "\n",
    "./create_container.sh pytorch-fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-steam",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The FAIRSeq image has been pushed into Amazon ECR, the registry from which Amazon SageMaker will be able to pull that image and launch both training and prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-stock",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training on Amazon SageMaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-commercial",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Next we will set the hyper-parameters of the model we want to train. Here we are using the recommended ones from the [FAIRSeq example](https://github.com/pytorch/fairseq/tree/master/examples/translation#prepare-iwslt14sh). The full list of hyper-parameters available for use can be found [here](https://fairseq.readthedocs.io/en/latest/command_line_tools.html). Please note you can use dataset, training, and generation parameters. For the distributed backend, **gloo** is the only supported option and is set as default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-protection",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\": 0.25,\n",
    "    \"clip-norm\": 0.1,\n",
    "    \"dropout\": 0.2,\n",
    "    \"max-tokens\": 4000,\n",
    "    \"criterion\": \"label_smoothed_cross_entropy\",\n",
    "    \"label-smoothing\": 0.1,\n",
    "    \"lr-scheduler\": \"fixed\",\n",
    "    \"force-anneal\": 200,\n",
    "    \"arch\": \"fconv_iwslt_de_en\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-quest",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We are ready to define the Estimator, which will encapsulate all the required parameters needed for launching the training on Amazon SageMaker. \n",
    "\n",
    "For training, the FAIRSeq toolkit recommends to train on GPU instances, such as the `ml.p3` instance family [available in Amazon SageMaker](https://aws.amazon.com/sagemaker/pricing/instance-types/). In this example, we are training on 2 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-proposal",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "algorithm_name = \"pytorch-fairseq\"\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, algorithm_name)\n",
    "\n",
    "estimator = Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    train_instance_count=2,\n",
    "    train_instance_type=\"ml.p3.8xlarge\",\n",
    "    train_volume_size=100,\n",
    "    output_path=\"s3://{}/output\".format(bucket),\n",
    "    hyperparameters=hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-duncan",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The call to fit will launch the training job and regularly report on the different performance metrics related to the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-caution",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-joseph",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Once the model has finished training, we can go ahead and test its translation capabilities by deploying it on an endpoint.\n",
    "\n",
    "## Hosting the model\n",
    "\n",
    "We first need to define a base JSONPredictor class that will help us with sending predictions to the model once it's hosted on the Amazon SageMaker endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-vancouver",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "\n",
    "class JSONPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(\n",
    "            endpoint_name, sagemaker_session, json_serializer, json_deserializer\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-response",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We can now use the estimator object to deploy the model artificats (the trained model), and deploy it on a CPU instance as we no longer need a GPU instance for simply infering from the model. Let's use a `ml.m5.xlarge`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-receipt",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.xlarge\", predictor_cls=JSONPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-property",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Now it's your time to play. Input a sentence in German and get the translation in English by simply calling predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-accent",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "text_input = \"Guten Morgen\"\n",
    "\n",
    "result = predictor.predict(text_input)\n",
    "#  Some characters are escaped HTML-style requiring to unescape them before printing\n",
    "print(html.unescape(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-stamp",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Once you're done with getting predictions, remember to shut down your endpoint as you no longer need it. \n",
    "\n",
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-neighbor",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-atlanta",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Voila! For more information, you can check out the [FAIRSeq toolkit homepage](https://github.com/pytorch/fairseq). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.664286,
   "end_time": "2021-06-17T00:16:11.342359",
   "environment_variables": {},
   "exception": true,
   "input_path": "fairseq_sagemaker_distributed_translate_de2en.ipynb",
   "output_path": "/opt/ml/processing/output/fairseq_sagemaker_distributed_translate_de2en-2021-06-17-00-11-49.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-17T00:15:59.678073",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
